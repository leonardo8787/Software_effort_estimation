{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret\n",
    "\n",
    "O PyCaret é uma biblioteca de aprendizado de máquina em Python que simplifica a construção, treinamento, ajuste e implementação de modelos de machine learning. Ele automatiza grande parte do processo de modelagem, permitindo que você crie modelos complexos com apenas algumas linhas de código.\n",
    "\n",
    "Principais Funcionalidades do PyCaret:\n",
    "Automatização do Fluxo de Trabalho de Machine Learning:\n",
    "\n",
    "Pré-processamento de dados (limpeza, transformação, normalização).\n",
    "Treinamento de múltiplos modelos com diferentes algoritmos.\n",
    "Comparação de modelos usando métricas padrão.\n",
    "Ajuste fino (tuning) dos hiperparâmetros.\n",
    "Modelos Preditivos:\n",
    "\n",
    "PyCaret suporta algoritmos de classificação, regressão, clustering, detecção de anomalias, e séries temporais.\n",
    "Pipeline Integrado:\n",
    "\n",
    "Todo o fluxo de trabalho é encapsulado em um pipeline, garantindo que as etapas de transformação de dados sejam consistentes durante a previsão e produção.\n",
    "Interpretação de Modelos:\n",
    "\n",
    "PyCaret fornece ferramentas para interpretar modelos, visualizar importância de variáveis e analisar predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.utils.validation import check_X_y\n",
    "import numpy as np\n",
    "\n",
    "# Função para carregar datasets\n",
    "def load_datasets(directory='dataset'):\n",
    "    datasets = {}\n",
    "    \n",
    "    # Verifica se o diretório existe\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Diretório '{directory}' não encontrado.\")\n",
    "        return datasets\n",
    "\n",
    "    # Percorre todos os arquivos do diretório\n",
    "    for file in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, file)\n",
    "        filename, ext = os.path.splitext(file)\n",
    "\n",
    "        try:\n",
    "            # Detecta delimitador automaticamente\n",
    "            if ext == '.txt':\n",
    "                with open(filepath, 'r') as f:\n",
    "                    first_line = f.readline()\n",
    "                    delimiter = ',' if ',' in first_line else ('\\t' if '\\t' in first_line else ' ')\n",
    "                datasets[filename] = pd.read_csv(filepath, delimiter=delimiter)\n",
    "                print(f\"{filename}: Delimitador detectado - '{delimiter}'\")\n",
    "                print(datasets[filename].head())  # Exibe as primeiras linhas do dataframe\n",
    "            else:\n",
    "                print(f\"Formato não suportado: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {file}: {e}\")\n",
    "    \n",
    "    print(f\"{len(datasets)} arquivos carregados com sucesso.\")\n",
    "    return datasets\n",
    "\n",
    "# Função para treinar e testar modelos de regressão com validação cruzada\n",
    "def test_regression_models(data):\n",
    "    models = {\n",
    "        'LinearRegression': LinearRegression(),\n",
    "        'Ridge': Ridge(),\n",
    "        'Lasso': Lasso(),\n",
    "        'RandomForest': RandomForestRegressor(),\n",
    "        'GradientBoosting': GradientBoostingRegressor()\n",
    "    }\n",
    "    \n",
    "    param_grid = {\n",
    "        'LinearRegression': {},\n",
    "        'Ridge': {'alpha': [0.1, 1, 10]},\n",
    "        'Lasso': {'alpha': [0.1, 0.5, 1]},\n",
    "        'RandomForest': {'n_estimators': [50, 100, 200]},\n",
    "        'GradientBoosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, df in data.items():\n",
    "        # Remove valores nulos\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Verifica se há dados suficientes\n",
    "        if df.shape[0] < 2 or df.shape[1] < 2:\n",
    "            print(f\"{name}: Dataset insuficiente para treino. Tamanho: {df.shape}\")\n",
    "            continue\n",
    "        \n",
    "        X = df.iloc[:, :-1]  # Todas as colunas menos a última\n",
    "        y = df.iloc[:, -1]   # Última coluna como alvo\n",
    "        \n",
    "        try:\n",
    "            # Validação do X e y\n",
    "            X, y = check_X_y(X, y)\n",
    "        except ValueError as e:\n",
    "            print(f\"{name}: Erro de validação dos dados - {e}\")\n",
    "            continue\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            grid = GridSearchCV(model, param_grid[model_name], cv=5, scoring='neg_mean_squared_error', error_score='raise')\n",
    "            try:\n",
    "                grid.fit(X_train, y_train)\n",
    "                best_model = grid.best_estimator_\n",
    "\n",
    "                # Validação cruzada\n",
    "                mse_scores = -cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "                r2_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='r2')\n",
    "                \n",
    "                mse = np.mean(mse_scores)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = np.mean(r2_scores)\n",
    "\n",
    "                results[f'{name}_{model_name}'] = {\n",
    "                    'mse': mse,\n",
    "                    'rmse': rmse,\n",
    "                    'r2_score': r2,\n",
    "                    'best_params': grid.best_params_\n",
    "                }\n",
    "                print(f\"{name} - {model_name}: MSE = {mse:.4f}, RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{name} - {model_name}: Falha no treinamento - {e}\")\n",
    "    \n",
    "    # Salva resultados em um arquivo Excel\n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    results_df.to_excel('regression_results.xlsx')\n",
    "    print(\"Resultados salvos em 'regression_results.xlsx'.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Exemplo de uso\n",
    "data = load_datasets()\n",
    "results = test_regression_models(data)\n",
    "for model, result in results.items():\n",
    "    print(f\"{model}: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
