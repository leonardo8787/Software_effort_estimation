{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script em python para ordenar os melhores resultados das tabelas xlsx, para verificar quais foram as melhores abordagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído! Relatório salvo em: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\processamento\\ordena-resultados\\8-ordenacao_modelos_selectkbest-75.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Diretório base (modifique conforme necessário)\n",
    "base_directory = r'C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\4-escolha\\selectKbest\\75'\n",
    "output_txt_file = r'C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\processamento\\ordena-resultados\\8-ordenacao_modelos_selectkbest-75.txt'\n",
    "\n",
    "# Lista para armazenar os dados combinados\n",
    "all_data = []\n",
    "\n",
    "# Busca recursiva por TODOS os arquivos .xlsx nas subpastas\n",
    "for excel_file in glob(os.path.join(base_directory, '**/*.xlsx'), recursive=True):\n",
    "    try:\n",
    "        # Lê o arquivo Excel\n",
    "        df = pd.read_excel(excel_file)\n",
    "        \n",
    "        # Adiciona metadados do arquivo\n",
    "        df['file_path'] = excel_file  # Caminho completo\n",
    "        \n",
    "        # Extrai nome do dataset do caminho (exemplo: \"maxwell\", \"cocomo81\")\n",
    "        dataset = next((d for d in ['maxwell', 'cocomo81', 'desharnais', 'china'] \n",
    "                        if d in excel_file.lower()), 'outro')\n",
    "        df['dataset'] = dataset\n",
    "        \n",
    "        # Adiciona à lista principal\n",
    "        all_data.append(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {excel_file}: {str(e)}\")\n",
    "\n",
    "# Combina todos os dados em um único DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Função para gerar relatórios de ordenação\n",
    "def generate_ranking_report(df, metric, ascending=True):\n",
    "    return df.sort_values(by=metric, ascending=ascending)['file_path'].unique()\n",
    "\n",
    "# Gera relatório completo\n",
    "with open(output_txt_file, 'w') as report:\n",
    "    for dataset in combined_df['dataset'].unique():\n",
    "        dataset_df = combined_df[combined_df['dataset'] == dataset]\n",
    "        \n",
    "        report.write(f\"\\n{'='*50}\\nDataset: {dataset.upper()}\\n{'='*50}\\n\")\n",
    "        \n",
    "        # Metricas para ordenação\n",
    "        metrics_config = {\n",
    "            'MSE (Ascendente)': ('mse', True),\n",
    "            'RMSE (Ascendente)': ('rmse', True),\n",
    "            'MAE (Ascendente)': ('mae', True),\n",
    "            'R² (Descendente)': ('r2', False)\n",
    "        }\n",
    "        \n",
    "        for title, (metric, order) in metrics_config.items():\n",
    "            ranked_files = generate_ranking_report(dataset_df, metric, order)\n",
    "            report.write(f\"\\n{title}:\\n\")\n",
    "            for rank, path in enumerate(ranked_files[:10], 1):  # Top 10\n",
    "                report.write(f\"{rank}. {os.path.relpath(path, base_directory)}\\n\")\n",
    "\n",
    "print(\"Processamento concluído! Relatório salvo em:\", output_txt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pega as melhores abordagens descritas no processo anterior e encontra a melhor, reuni todas em uma única tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao analisar a métrica mse: \"['subdir'] not in index\"\n",
      "Erro ao analisar a métrica rmse: \"['subdir'] not in index\"\n",
      "Erro ao analisar a métrica mae: \"['subdir'] not in index\"\n",
      "Erro ao analisar a métrica r2: \"['subdir'] not in index\"\n",
      "Processamento concluído! Dados combinados e análise de melhores abordagens salvos em:\n",
      "- Dados combinados: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\combined_results_analysis.xlsx\n",
      "- Resumo de métricas: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\metrics_summary_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Diretório base (modifique conforme necessário)\n",
    "base_directory = r'C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal'\n",
    "output_excel_file = os.path.join(base_directory, 'combined_results_analysis.xlsx')\n",
    "\n",
    "# Subdiretórios de interesse\n",
    "subdirs = [\n",
    "    '1-tratamento',\n",
    "    '2-MIMIC-25', '2-MIMIC-75', '2-GAN-75', '2-GAN-50',\n",
    "    '3-simulacao\\GAN-75', '3-simulacao\\MIMIC-25', '3-simulacao\\MIMIC-50', '3-simulacao\\MIMIC-75'\n",
    "]\n",
    "\n",
    "# Lista para armazenar os dados combinados\n",
    "all_data = []\n",
    "\n",
    "# Busca recursiva por arquivos relevantes em cada subdiretório\n",
    "for subdir in subdirs:\n",
    "    full_path = os.path.join(base_directory, subdir)\n",
    "    for excel_file in glob(os.path.join(full_path, '**/*.xlsx'), recursive=True):\n",
    "        try:\n",
    "            # Lê o arquivo Excel\n",
    "            df = pd.read_excel(excel_file)\n",
    "            \n",
    "            # Adiciona metadados do arquivo\n",
    "            df['file_path'] = excel_file  # Caminho completo\n",
    "            df['subdir'] = subdir  # Subdiretório relativo\n",
    "            \n",
    "            # Extrai nome do dataset do caminho (exemplo: \"maxwell\", \"cocomo81\")\n",
    "            dataset = next((d for d in ['maxwell', 'cocomo81', 'desharnais', 'china'] \n",
    "                            if d in excel_file.lower()), 'outro')\n",
    "            df['dataset'] = dataset\n",
    "            \n",
    "            # Adiciona à lista principal\n",
    "            all_data.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {excel_file}: {str(e)}\")\n",
    "\n",
    "# Salva a tabela combinada em um único arquivo Excel\n",
    "combined_df.to_excel(output_excel_file, index=False)\n",
    "\n",
    "# Análise de melhores abordagens\n",
    "metrics = ['mse', 'rmse', 'mae', 'r2']\n",
    "results_summary = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    try:\n",
    "        # Para cada métrica, encontra a abordagem com o melhor valor\n",
    "        if metric in combined_df.columns:\n",
    "            best_row = combined_df.loc[combined_df[metric].idxmin()] if metric != 'r2' else combined_df.loc[combined_df[metric].idxmax()]\n",
    "            results_summary[metric] = best_row[['dataset', 'subdir', 'file_path', metric]]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao analisar a métrica {metric}: {str(e)}\")\n",
    "\n",
    "# Salva os resultados resumidos também no Excel\n",
    "summary_df = pd.DataFrame.from_dict(results_summary, orient='index')\n",
    "summary_file = os.path.join(base_directory, 'metrics_summary_analysis.xlsx')\n",
    "summary_df.to_excel(summary_file)\n",
    "\n",
    "print(\"Processamento concluído! Dados combinados e análise de melhores abordagens salvos em:\")\n",
    "print(f\"- Dados combinados: {output_excel_file}\")\n",
    "print(f\"- Resumo de métricas: {summary_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
