{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria simulação (Geração de amostras Sintéticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo dataset: tratamento_china.txt\n",
      "Lendo dataset: tratamento_cocomo81.txt\n",
      "Lendo dataset: tratamento_desharnais.txt\n",
      "Lendo dataset: tratamento_maxwell.txt\n",
      "Gerando 2500 amostras sintéticas para tratamento_china...\n",
      "Epoch [0/5000] - Loss D: 1.3442, Loss G: 0.6790\n",
      "Epoch [500/5000] - Loss D: 0.3864, Loss G: 2.2634\n",
      "Epoch [1000/5000] - Loss D: 0.3813, Loss G: 2.5238\n",
      "Epoch [1500/5000] - Loss D: 0.2655, Loss G: 3.2843\n",
      "Epoch [2000/5000] - Loss D: 0.3484, Loss G: 3.4396\n",
      "Epoch [2500/5000] - Loss D: 0.3255, Loss G: 2.7824\n",
      "Epoch [3000/5000] - Loss D: 0.1266, Loss G: 3.8165\n",
      "Epoch [3500/5000] - Loss D: 0.1032, Loss G: 4.1187\n",
      "Epoch [4000/5000] - Loss D: 0.0957, Loss G: 4.3513\n",
      "Epoch [4500/5000] - Loss D: 0.0801, Loss G: 3.7662\n",
      "Epoch [4999/5000] - Loss D: 0.2042, Loss G: 4.0304\n",
      "Amostras normalizadas salvas em C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\1-tratamento\\tratamento_china.txt\n",
      "Gerando 2500 amostras sintéticas para tratamento_cocomo81...\n",
      "Epoch [0/5000] - Loss D: 1.4134, Loss G: 0.7276\n",
      "Epoch [500/5000] - Loss D: 1.4925, Loss G: 0.6590\n",
      "Epoch [1000/5000] - Loss D: 1.3595, Loss G: 0.7129\n",
      "Epoch [1500/5000] - Loss D: 1.5656, Loss G: 0.7930\n",
      "Epoch [2000/5000] - Loss D: 1.3144, Loss G: 0.7216\n",
      "Epoch [2500/5000] - Loss D: 1.5604, Loss G: 0.6892\n",
      "Epoch [3000/5000] - Loss D: 1.4332, Loss G: 0.7008\n",
      "Epoch [3500/5000] - Loss D: 1.3150, Loss G: 0.7285\n",
      "Epoch [4000/5000] - Loss D: 0.9377, Loss G: 0.9389\n",
      "Epoch [4500/5000] - Loss D: 1.1740, Loss G: 0.8156\n",
      "Epoch [4999/5000] - Loss D: 1.2037, Loss G: 0.6935\n",
      "Amostras normalizadas salvas em C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\1-tratamento\\tratamento_cocomo81.txt\n",
      "Gerando 2500 amostras sintéticas para tratamento_desharnais...\n",
      "Epoch [0/5000] - Loss D: 1.3737, Loss G: 0.7115\n",
      "Epoch [500/5000] - Loss D: 0.9755, Loss G: 1.0685\n",
      "Epoch [1000/5000] - Loss D: 1.4463, Loss G: 0.7883\n",
      "Epoch [1500/5000] - Loss D: 1.2192, Loss G: 0.8054\n",
      "Epoch [2000/5000] - Loss D: 1.1895, Loss G: 0.7277\n",
      "Epoch [2500/5000] - Loss D: 1.1898, Loss G: 0.9495\n",
      "Epoch [3000/5000] - Loss D: 1.3272, Loss G: 1.1094\n",
      "Epoch [3500/5000] - Loss D: 1.1421, Loss G: 0.9904\n",
      "Epoch [4000/5000] - Loss D: 1.3268, Loss G: 1.3270\n",
      "Epoch [4500/5000] - Loss D: 1.0325, Loss G: 1.0332\n",
      "Epoch [4999/5000] - Loss D: 0.8048, Loss G: 1.2790\n",
      "Amostras normalizadas salvas em C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\1-tratamento\\tratamento_desharnais.txt\n",
      "Gerando 2500 amostras sintéticas para tratamento_maxwell...\n",
      "Epoch [0/5000] - Loss D: 1.3896, Loss G: 0.6985\n",
      "Epoch [500/5000] - Loss D: 1.3550, Loss G: 0.7485\n",
      "Epoch [1000/5000] - Loss D: 1.8668, Loss G: 0.7174\n",
      "Epoch [1500/5000] - Loss D: 1.3437, Loss G: 0.8159\n",
      "Epoch [2000/5000] - Loss D: 1.7408, Loss G: 0.6817\n",
      "Epoch [2500/5000] - Loss D: 1.9563, Loss G: 0.7276\n",
      "Epoch [3000/5000] - Loss D: 1.4644, Loss G: 0.7993\n",
      "Epoch [3500/5000] - Loss D: 1.3763, Loss G: 0.6789\n",
      "Epoch [4000/5000] - Loss D: 1.4919, Loss G: 0.8819\n",
      "Epoch [4500/5000] - Loss D: 0.8609, Loss G: 1.1800\n",
      "Epoch [4999/5000] - Loss D: 1.2312, Loss G: 0.8005\n",
      "Amostras normalizadas salvas em C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\1-tratamento\\tratamento_maxwell.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configuração da semente para reprodutibilidade\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Definir a arquitetura da GAN\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Função para treinar a GAN\n",
    "def train_gan(real_data, num_features, latent_dim, num_samples, num_epochs=5000, batch_size=32):\n",
    "    # Normalizar os dados reais\n",
    "    scaler = MinMaxScaler()\n",
    "    try:\n",
    "        real_data = scaler.fit_transform(real_data)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Erro na normalização dos dados reais: {e}\")\n",
    "\n",
    "    # Converter para tensores\n",
    "    real_data = torch.tensor(real_data, dtype=torch.float32)\n",
    "\n",
    "    # Inicializar o gerador e o discriminador\n",
    "    generator = Generator(latent_dim, num_features)\n",
    "    discriminator = Discriminator(num_features)\n",
    "\n",
    "    # Definir otimizadores e função de perda\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Treinar o discriminador\n",
    "        for _ in range(max(1, real_data.size(0) // batch_size)):\n",
    "            idx = np.random.randint(0, real_data.size(0), batch_size)\n",
    "            real_samples = real_data[idx]\n",
    "\n",
    "            # Labels reais e falsos\n",
    "            real_labels = torch.ones((real_samples.size(0), 1))\n",
    "            fake_labels = torch.zeros((real_samples.size(0), 1))\n",
    "\n",
    "            # Amostras do gerador\n",
    "            noise = torch.randn((real_samples.size(0), latent_dim))\n",
    "            fake_samples = generator(noise)\n",
    "\n",
    "            # Predições do discriminador\n",
    "            real_preds = discriminator(real_samples)\n",
    "            fake_preds = discriminator(fake_samples.detach())\n",
    "\n",
    "            # Perda do discriminador\n",
    "            loss_real = criterion(real_preds, real_labels)\n",
    "            loss_fake = criterion(fake_preds, fake_labels)\n",
    "            loss_D = loss_real + loss_fake\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # Treinar o gerador\n",
    "        noise = torch.randn((batch_size, latent_dim))\n",
    "        fake_samples = generator(noise)\n",
    "        fake_preds = discriminator(fake_samples)\n",
    "        loss_G = criterion(fake_preds, torch.ones((batch_size, 1)))\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Exibir progresso\n",
    "        if epoch % 500 == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] - Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "\n",
    "    # Gerar novas amostras sintéticas\n",
    "    noise = torch.randn((num_samples, latent_dim))\n",
    "    synthetic_data = generator(noise).detach().numpy()\n",
    "\n",
    "    # Reverter a normalização\n",
    "    synthetic_data = scaler.inverse_transform(synthetic_data)\n",
    "    return synthetic_data\n",
    "\n",
    "# Função principal para processar múltiplos datasets\n",
    "def generate_synthetic_samples(input_directory, output_directory, total_samples=10000):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Carregar datasets\n",
    "    datasets = {}\n",
    "    for file in os.listdir(input_directory):\n",
    "        filepath = os.path.join(input_directory, file)\n",
    "        filename, ext = os.path.splitext(file)\n",
    "        if ext == '.txt':\n",
    "            try:\n",
    "                print(f\"Lendo dataset: {file}\")\n",
    "                df = pd.read_csv(filepath, delimiter=',')\n",
    "                df = df.apply(pd.to_numeric, errors='coerce')  # Forçar conversão para numérico\n",
    "                df = df.dropna()  # Remover linhas com valores não numéricos\n",
    "                if not df.empty:\n",
    "                    datasets[filename] = df\n",
    "                else:\n",
    "                    print(f\"{file} está vazio após limpeza.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao carregar {file}: {e}\")\n",
    "\n",
    "    if not datasets:\n",
    "        print(\"Nenhum dataset válido encontrado. Encerrando...\")\n",
    "        return\n",
    "\n",
    "    # Gerar amostras sintéticas para cada dataset\n",
    "    for name, df in datasets.items():\n",
    "        num_features = df.shape[1]\n",
    "        samples_per_dataset = max(1, total_samples // len(datasets))\n",
    "        latent_dim = 10  # Dimensão do espaço latente\n",
    "\n",
    "        print(f\"Gerando {samples_per_dataset} amostras sintéticas para {name}...\")\n",
    "        try:\n",
    "            synthetic_data = train_gan(df.values, num_features, latent_dim, samples_per_dataset)\n",
    "\n",
    "            # Verificar se já existe um arquivo de saída\n",
    "            output_path = os.path.join(output_directory, f\"{name}.txt\")\n",
    "            if os.path.exists(output_path):\n",
    "                existing_data = pd.read_csv(output_path, delimiter=',')\n",
    "                existing_data['source'] = 'original'\n",
    "            else:\n",
    "                existing_data = df.copy()\n",
    "                existing_data['source'] = 'original'\n",
    "\n",
    "            synthetic_df = pd.DataFrame(synthetic_data, columns=df.columns)\n",
    "            synthetic_df['source'] = 'synthetic'\n",
    "\n",
    "            # Combinar os dados originais e sintéticos\n",
    "            combined_data = pd.concat([existing_data, synthetic_df], ignore_index=True)\n",
    "\n",
    "            # Normalizar os dados combinados\n",
    "            scaler = MinMaxScaler()\n",
    "            normalized_data = scaler.fit_transform(combined_data.drop(columns=['source']))\n",
    "            normalized_df = pd.DataFrame(normalized_data, columns=combined_data.columns[:-1])\n",
    "            normalized_df['source'] = combined_data['source'].values\n",
    "\n",
    "            # Salvar os dados normalizados\n",
    "            normalized_df.to_csv(output_path, sep=',', index=False)\n",
    "            print(f\"Amostras normalizadas salvas em {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao gerar amostras para {name}: {e}\")\n",
    "\n",
    "# Diretórios de entrada e saída\n",
    "input_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\1-tratamento-target-encoding-normalizado\"\n",
    "output_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\1-tratamento\"\n",
    "\n",
    "# Gerar amostras sintéticas\n",
    "generate_synthetic_samples(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-25\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.3000, Loss G: 0.6778\n",
      "Epoch [500/5000] - Loss D: 0.0606, Loss G: 6.1753\n",
      "Epoch [1000/5000] - Loss D: 0.2736, Loss G: 3.0633\n",
      "Epoch [1500/5000] - Loss D: 0.0870, Loss G: 5.5013\n",
      "Epoch [2000/5000] - Loss D: 0.1178, Loss G: 3.9183\n",
      "Epoch [2500/5000] - Loss D: 0.0381, Loss G: 6.2145\n",
      "Epoch [3000/5000] - Loss D: 0.0457, Loss G: 5.7248\n",
      "Epoch [3500/5000] - Loss D: 0.1342, Loss G: 4.6205\n",
      "Epoch [4000/5000] - Loss D: 0.0155, Loss G: 6.5867\n",
      "Epoch [4500/5000] - Loss D: 0.0190, Loss G: 5.7814\n",
      "Epoch [4999/5000] - Loss D: 0.0175, Loss G: 8.3241\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-25\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-25\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.4049, Loss G: 0.6834\n",
      "Epoch [500/5000] - Loss D: 1.5940, Loss G: 0.7133\n",
      "Epoch [1000/5000] - Loss D: 1.3331, Loss G: 1.0189\n",
      "Epoch [1500/5000] - Loss D: 1.2801, Loss G: 0.8641\n",
      "Epoch [2000/5000] - Loss D: 1.6843, Loss G: 0.6490\n",
      "Epoch [2500/5000] - Loss D: 1.4293, Loss G: 0.6768\n",
      "Epoch [3000/5000] - Loss D: 1.0139, Loss G: 1.0987\n",
      "Epoch [3500/5000] - Loss D: 1.7570, Loss G: 0.7764\n",
      "Epoch [4000/5000] - Loss D: 0.9710, Loss G: 1.2748\n",
      "Epoch [4500/5000] - Loss D: 1.4590, Loss G: 0.9716\n",
      "Epoch [4999/5000] - Loss D: 0.8772, Loss G: 1.0935\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-25\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-25\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3556, Loss G: 0.7043\n",
      "Epoch [500/5000] - Loss D: 0.9137, Loss G: 1.0205\n",
      "Epoch [1000/5000] - Loss D: 1.1293, Loss G: 1.0315\n",
      "Epoch [1500/5000] - Loss D: 0.5686, Loss G: 1.4739\n",
      "Epoch [2000/5000] - Loss D: 0.9891, Loss G: 1.2270\n",
      "Epoch [2500/5000] - Loss D: 1.0056, Loss G: 1.3014\n",
      "Epoch [3000/5000] - Loss D: 1.1159, Loss G: 1.2181\n",
      "Epoch [3500/5000] - Loss D: 1.2606, Loss G: 0.8430\n",
      "Epoch [4000/5000] - Loss D: 0.9675, Loss G: 1.1385\n",
      "Epoch [4500/5000] - Loss D: 0.7704, Loss G: 1.4130\n",
      "Epoch [4999/5000] - Loss D: 1.0747, Loss G: 0.9970\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-25\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-25\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.3975, Loss G: 0.6745\n",
      "Epoch [500/5000] - Loss D: 1.3952, Loss G: 0.6630\n",
      "Epoch [1000/5000] - Loss D: 1.4600, Loss G: 0.6602\n",
      "Epoch [1500/5000] - Loss D: 1.1798, Loss G: 0.7594\n",
      "Epoch [2000/5000] - Loss D: 1.3357, Loss G: 0.6703\n",
      "Epoch [2500/5000] - Loss D: 0.7400, Loss G: 1.4295\n",
      "Epoch [3000/5000] - Loss D: 0.8091, Loss G: 1.1753\n",
      "Epoch [3500/5000] - Loss D: 0.9316, Loss G: 1.2869\n",
      "Epoch [4000/5000] - Loss D: 0.9249, Loss G: 1.2530\n",
      "Epoch [4500/5000] - Loss D: 0.8723, Loss G: 1.2232\n",
      "Epoch [4999/5000] - Loss D: 1.3216, Loss G: 1.1665\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-25\\tratamento_maxwell.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-50\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.2780, Loss G: 0.7356\n",
      "Epoch [500/5000] - Loss D: 0.0227, Loss G: 6.4625\n",
      "Epoch [1000/5000] - Loss D: 0.0574, Loss G: 4.9273\n",
      "Epoch [1500/5000] - Loss D: 0.4583, Loss G: 3.7890\n",
      "Epoch [2000/5000] - Loss D: 0.0455, Loss G: 6.1615\n",
      "Epoch [2500/5000] - Loss D: 0.0776, Loss G: 7.9485\n",
      "Epoch [3000/5000] - Loss D: 0.0133, Loss G: 8.6810\n",
      "Epoch [3500/5000] - Loss D: 0.0136, Loss G: 6.5007\n",
      "Epoch [4000/5000] - Loss D: 0.0048, Loss G: 5.9902\n",
      "Epoch [4500/5000] - Loss D: 0.0122, Loss G: 6.6180\n",
      "Epoch [4999/5000] - Loss D: 0.0066, Loss G: 7.7715\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-50\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-50\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.3777, Loss G: 0.7026\n",
      "Epoch [500/5000] - Loss D: 1.2963, Loss G: 0.7790\n",
      "Epoch [1000/5000] - Loss D: 1.3107, Loss G: 0.5878\n",
      "Epoch [1500/5000] - Loss D: 1.0234, Loss G: 0.9025\n",
      "Epoch [2000/5000] - Loss D: 1.4855, Loss G: 0.7318\n",
      "Epoch [2500/5000] - Loss D: 1.3270, Loss G: 0.8272\n",
      "Epoch [3000/5000] - Loss D: 1.1377, Loss G: 0.6617\n",
      "Epoch [3500/5000] - Loss D: 0.7792, Loss G: 1.1957\n",
      "Epoch [4000/5000] - Loss D: 1.3745, Loss G: 0.9549\n",
      "Epoch [4500/5000] - Loss D: 0.9923, Loss G: 1.0239\n",
      "Epoch [4999/5000] - Loss D: 1.7671, Loss G: 1.2648\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-50\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-50\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3798, Loss G: 0.6881\n",
      "Epoch [500/5000] - Loss D: 0.9425, Loss G: 1.0553\n",
      "Epoch [1000/5000] - Loss D: 0.9355, Loss G: 1.0581\n",
      "Epoch [1500/5000] - Loss D: 1.2045, Loss G: 1.1399\n",
      "Epoch [2000/5000] - Loss D: 0.8641, Loss G: 1.1815\n",
      "Epoch [2500/5000] - Loss D: 1.1120, Loss G: 0.9660\n",
      "Epoch [3000/5000] - Loss D: 0.9832, Loss G: 1.0298\n",
      "Epoch [3500/5000] - Loss D: 1.0855, Loss G: 1.1271\n",
      "Epoch [4000/5000] - Loss D: 0.7591, Loss G: 1.1234\n",
      "Epoch [4500/5000] - Loss D: 0.8657, Loss G: 1.3575\n",
      "Epoch [4999/5000] - Loss D: 0.8904, Loss G: 1.0068\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-50\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-50\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.3734, Loss G: 0.6830\n",
      "Epoch [500/5000] - Loss D: 1.5504, Loss G: 0.6748\n",
      "Epoch [1000/5000] - Loss D: 1.3210, Loss G: 0.8285\n",
      "Epoch [1500/5000] - Loss D: 1.4527, Loss G: 1.1503\n",
      "Epoch [2000/5000] - Loss D: 1.3945, Loss G: 0.7460\n",
      "Epoch [2500/5000] - Loss D: 1.2011, Loss G: 0.8829\n",
      "Epoch [3000/5000] - Loss D: 1.3156, Loss G: 0.9974\n",
      "Epoch [3500/5000] - Loss D: 1.3186, Loss G: 0.8398\n",
      "Epoch [4000/5000] - Loss D: 1.1018, Loss G: 0.8411\n",
      "Epoch [4500/5000] - Loss D: 1.4458, Loss G: 0.7017\n",
      "Epoch [4999/5000] - Loss D: 1.4183, Loss G: 0.7774\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-50\\tratamento_maxwell.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-75\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.2607, Loss G: 0.6928\n",
      "Epoch [500/5000] - Loss D: 0.0157, Loss G: 7.3074\n",
      "Epoch [1000/5000] - Loss D: 0.0442, Loss G: 5.9785\n",
      "Epoch [1500/5000] - Loss D: 0.0968, Loss G: 5.3750\n",
      "Epoch [2000/5000] - Loss D: 0.0328, Loss G: 6.2321\n",
      "Epoch [2500/5000] - Loss D: 0.0277, Loss G: 7.2909\n",
      "Epoch [3000/5000] - Loss D: 0.0278, Loss G: 7.3095\n",
      "Epoch [3500/5000] - Loss D: 0.0164, Loss G: 7.4190\n",
      "Epoch [4000/5000] - Loss D: 0.0050, Loss G: 7.8586\n",
      "Epoch [4500/5000] - Loss D: 0.0375, Loss G: 7.4972\n",
      "Epoch [4999/5000] - Loss D: 0.0047, Loss G: 7.5507\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-75\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-75\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.4080, Loss G: 0.6723\n",
      "Epoch [500/5000] - Loss D: 1.2260, Loss G: 0.8779\n",
      "Epoch [1000/5000] - Loss D: 1.2072, Loss G: 0.8410\n",
      "Epoch [1500/5000] - Loss D: 1.0751, Loss G: 0.9595\n",
      "Epoch [2000/5000] - Loss D: 1.1869, Loss G: 0.9605\n",
      "Epoch [2500/5000] - Loss D: 1.2996, Loss G: 0.7656\n",
      "Epoch [3000/5000] - Loss D: 1.3126, Loss G: 0.8976\n",
      "Epoch [3500/5000] - Loss D: 0.9698, Loss G: 0.9984\n",
      "Epoch [4000/5000] - Loss D: 1.3233, Loss G: 1.0972\n",
      "Epoch [4500/5000] - Loss D: 1.3795, Loss G: 0.7501\n",
      "Epoch [4999/5000] - Loss D: 1.1598, Loss G: 0.9094\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-75\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-75\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3954, Loss G: 0.6607\n",
      "Epoch [500/5000] - Loss D: 0.6620, Loss G: 1.5444\n",
      "Epoch [1000/5000] - Loss D: 0.6999, Loss G: 1.4083\n",
      "Epoch [1500/5000] - Loss D: 1.2174, Loss G: 0.9139\n",
      "Epoch [2000/5000] - Loss D: 1.5970, Loss G: 1.0381\n",
      "Epoch [2500/5000] - Loss D: 1.0283, Loss G: 1.2293\n",
      "Epoch [3000/5000] - Loss D: 0.8262, Loss G: 1.2107\n",
      "Epoch [3500/5000] - Loss D: 0.7697, Loss G: 1.1669\n",
      "Epoch [4000/5000] - Loss D: 0.9059, Loss G: 1.3249\n",
      "Epoch [4500/5000] - Loss D: 0.9198, Loss G: 1.3651\n",
      "Epoch [4999/5000] - Loss D: 0.6714, Loss G: 1.3595\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-75\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\GAN-75\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.4081, Loss G: 0.6541\n",
      "Epoch [500/5000] - Loss D: 1.3025, Loss G: 0.7645\n",
      "Epoch [1000/5000] - Loss D: 1.1288, Loss G: 0.9529\n",
      "Epoch [1500/5000] - Loss D: 1.1289, Loss G: 0.9388\n",
      "Epoch [2000/5000] - Loss D: 1.2953, Loss G: 0.7573\n",
      "Epoch [2500/5000] - Loss D: 1.3377, Loss G: 0.7811\n",
      "Epoch [3000/5000] - Loss D: 0.9872, Loss G: 1.0500\n",
      "Epoch [3500/5000] - Loss D: 1.2833, Loss G: 1.2173\n",
      "Epoch [4000/5000] - Loss D: 0.9290, Loss G: 1.2638\n",
      "Epoch [4500/5000] - Loss D: 1.0462, Loss G: 1.2318\n",
      "Epoch [4999/5000] - Loss D: 1.2531, Loss G: 1.0576\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\GAN-75\\tratamento_maxwell.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-25\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.3466, Loss G: 0.7128\n",
      "Epoch [500/5000] - Loss D: 0.1553, Loss G: 3.1528\n",
      "Epoch [1000/5000] - Loss D: 0.3089, Loss G: 3.2508\n",
      "Epoch [1500/5000] - Loss D: 0.2290, Loss G: 2.3497\n",
      "Epoch [2000/5000] - Loss D: 0.2043, Loss G: 2.9751\n",
      "Epoch [2500/5000] - Loss D: 0.1171, Loss G: 5.1669\n",
      "Epoch [3000/5000] - Loss D: 0.0935, Loss G: 4.1026\n",
      "Epoch [3500/5000] - Loss D: 0.2216, Loss G: 3.7329\n",
      "Epoch [4000/5000] - Loss D: 0.0317, Loss G: 6.3627\n",
      "Epoch [4500/5000] - Loss D: 0.0505, Loss G: 6.1658\n",
      "Epoch [4999/5000] - Loss D: 0.0393, Loss G: 5.3766\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-25\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-25\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.3938, Loss G: 0.6482\n",
      "Epoch [500/5000] - Loss D: 1.4699, Loss G: 0.5276\n",
      "Epoch [1000/5000] - Loss D: 1.3193, Loss G: 0.7475\n",
      "Epoch [1500/5000] - Loss D: 1.2555, Loss G: 0.6662\n",
      "Epoch [2000/5000] - Loss D: 1.2811, Loss G: 0.8950\n",
      "Epoch [2500/5000] - Loss D: 1.2024, Loss G: 0.9239\n",
      "Epoch [3000/5000] - Loss D: 1.3821, Loss G: 0.7637\n",
      "Epoch [3500/5000] - Loss D: 1.0245, Loss G: 0.9934\n",
      "Epoch [4000/5000] - Loss D: 1.1685, Loss G: 1.1508\n",
      "Epoch [4500/5000] - Loss D: 1.1654, Loss G: 0.8930\n",
      "Epoch [4999/5000] - Loss D: 1.3277, Loss G: 0.8705\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-25\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-25\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3849, Loss G: 0.7239\n",
      "Epoch [500/5000] - Loss D: 1.1995, Loss G: 0.9619\n",
      "Epoch [1000/5000] - Loss D: 1.0725, Loss G: 0.9923\n",
      "Epoch [1500/5000] - Loss D: 1.2908, Loss G: 0.9201\n",
      "Epoch [2000/5000] - Loss D: 1.1194, Loss G: 1.0738\n",
      "Epoch [2500/5000] - Loss D: 1.2477, Loss G: 1.0901\n",
      "Epoch [3000/5000] - Loss D: 1.0274, Loss G: 1.1682\n",
      "Epoch [3500/5000] - Loss D: 1.1449, Loss G: 1.0329\n",
      "Epoch [4000/5000] - Loss D: 1.0531, Loss G: 1.1339\n",
      "Epoch [4500/5000] - Loss D: 1.0702, Loss G: 1.0459\n",
      "Epoch [4999/5000] - Loss D: 1.0619, Loss G: 0.7987\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-25\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-25\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.3389, Loss G: 0.6506\n",
      "Epoch [500/5000] - Loss D: 1.3798, Loss G: 0.6835\n",
      "Epoch [1000/5000] - Loss D: 1.2443, Loss G: 1.0067\n",
      "Epoch [1500/5000] - Loss D: 0.9075, Loss G: 0.9675\n",
      "Epoch [2000/5000] - Loss D: 0.8936, Loss G: 1.0160\n",
      "Epoch [2500/5000] - Loss D: 1.0074, Loss G: 1.1126\n",
      "Epoch [3000/5000] - Loss D: 1.3532, Loss G: 1.3768\n",
      "Epoch [3500/5000] - Loss D: 0.7670, Loss G: 1.5143\n",
      "Epoch [4000/5000] - Loss D: 0.9160, Loss G: 1.3310\n",
      "Epoch [4500/5000] - Loss D: 0.8409, Loss G: 1.2096\n",
      "Epoch [4999/5000] - Loss D: 1.2907, Loss G: 0.9447\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-25\\tratamento_maxwell.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-50\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.3147, Loss G: 0.7527\n",
      "Epoch [500/5000] - Loss D: 0.2645, Loss G: 3.9048\n",
      "Epoch [1000/5000] - Loss D: 0.2938, Loss G: 3.2685\n",
      "Epoch [1500/5000] - Loss D: 0.0976, Loss G: 3.6004\n",
      "Epoch [2000/5000] - Loss D: 0.1023, Loss G: 4.7760\n",
      "Epoch [2500/5000] - Loss D: 0.2840, Loss G: 3.5563\n",
      "Epoch [3000/5000] - Loss D: 0.0216, Loss G: 5.2605\n",
      "Epoch [3500/5000] - Loss D: 0.0431, Loss G: 4.3216\n",
      "Epoch [4000/5000] - Loss D: 0.0120, Loss G: 5.6830\n",
      "Epoch [4500/5000] - Loss D: 0.0079, Loss G: 7.0005\n",
      "Epoch [4999/5000] - Loss D: 0.0380, Loss G: 4.5495\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-50\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-50\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.3739, Loss G: 0.6424\n",
      "Epoch [500/5000] - Loss D: 1.3798, Loss G: 0.7084\n",
      "Epoch [1000/5000] - Loss D: 1.3265, Loss G: 0.8340\n",
      "Epoch [1500/5000] - Loss D: 0.9843, Loss G: 1.0425\n",
      "Epoch [2000/5000] - Loss D: 0.7256, Loss G: 1.4684\n",
      "Epoch [2500/5000] - Loss D: 1.5314, Loss G: 0.9490\n",
      "Epoch [3000/5000] - Loss D: 1.0637, Loss G: 1.1655\n",
      "Epoch [3500/5000] - Loss D: 1.0875, Loss G: 0.9907\n",
      "Epoch [4000/5000] - Loss D: 1.2846, Loss G: 0.6956\n",
      "Epoch [4500/5000] - Loss D: 0.9458, Loss G: 1.1853\n",
      "Epoch [4999/5000] - Loss D: 1.2934, Loss G: 0.7441\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-50\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-50\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3492, Loss G: 0.7138\n",
      "Epoch [500/5000] - Loss D: 0.6781, Loss G: 1.5308\n",
      "Epoch [1000/5000] - Loss D: 0.9039, Loss G: 1.2935\n",
      "Epoch [1500/5000] - Loss D: 1.1718, Loss G: 1.2688\n",
      "Epoch [2000/5000] - Loss D: 0.9333, Loss G: 1.1855\n",
      "Epoch [2500/5000] - Loss D: 1.1766, Loss G: 0.8893\n",
      "Epoch [3000/5000] - Loss D: 0.9499, Loss G: 1.1239\n",
      "Epoch [3500/5000] - Loss D: 0.9364, Loss G: 1.1974\n",
      "Epoch [4000/5000] - Loss D: 0.9162, Loss G: 0.9639\n",
      "Epoch [4500/5000] - Loss D: 0.9015, Loss G: 1.2005\n",
      "Epoch [4999/5000] - Loss D: 0.8600, Loss G: 1.0723\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-50\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-50\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.3869, Loss G: 0.6905\n",
      "Epoch [500/5000] - Loss D: 1.5072, Loss G: 0.6658\n",
      "Epoch [1000/5000] - Loss D: 1.0470, Loss G: 1.0668\n",
      "Epoch [1500/5000] - Loss D: 0.7198, Loss G: 1.4032\n",
      "Epoch [2000/5000] - Loss D: 1.1495, Loss G: 0.8509\n",
      "Epoch [2500/5000] - Loss D: 1.3011, Loss G: 0.9832\n",
      "Epoch [3000/5000] - Loss D: 0.9389, Loss G: 1.2462\n",
      "Epoch [3500/5000] - Loss D: 1.2403, Loss G: 0.8797\n",
      "Epoch [4000/5000] - Loss D: 0.9071, Loss G: 1.5507\n",
      "Epoch [4500/5000] - Loss D: 0.8630, Loss G: 1.4474\n",
      "Epoch [4999/5000] - Loss D: 1.6958, Loss G: 1.0580\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-50\\tratamento_maxwell.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-75\\tratamento_china.txt\n",
      "Epoch [0/5000] - Loss D: 1.3331, Loss G: 0.7207\n",
      "Epoch [500/5000] - Loss D: 0.1573, Loss G: 4.2068\n",
      "Epoch [1000/5000] - Loss D: 0.1291, Loss G: 3.8724\n",
      "Epoch [1500/5000] - Loss D: 0.1025, Loss G: 4.2018\n",
      "Epoch [2000/5000] - Loss D: 0.1070, Loss G: 3.6169\n",
      "Epoch [2500/5000] - Loss D: 0.0171, Loss G: 4.8327\n",
      "Epoch [3000/5000] - Loss D: 0.0105, Loss G: 6.1685\n",
      "Epoch [3500/5000] - Loss D: 0.0260, Loss G: 5.3179\n",
      "Epoch [4000/5000] - Loss D: 0.0079, Loss G: 5.6668\n",
      "Epoch [4500/5000] - Loss D: 0.0191, Loss G: 5.4038\n",
      "Epoch [4999/5000] - Loss D: 0.0067, Loss G: 6.4044\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-75\\tratamento_china.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-75\\tratamento_cocomo81.txt\n",
      "Epoch [0/5000] - Loss D: 1.3693, Loss G: 0.6652\n",
      "Epoch [500/5000] - Loss D: 1.3031, Loss G: 0.7253\n",
      "Epoch [1000/5000] - Loss D: 1.1362, Loss G: 1.0459\n",
      "Epoch [1500/5000] - Loss D: 1.1771, Loss G: 0.8273\n",
      "Epoch [2000/5000] - Loss D: 1.5220, Loss G: 0.9283\n",
      "Epoch [2500/5000] - Loss D: 1.3337, Loss G: 0.9860\n",
      "Epoch [3000/5000] - Loss D: 1.1053, Loss G: 0.8849\n",
      "Epoch [3500/5000] - Loss D: 0.8966, Loss G: 1.0662\n",
      "Epoch [4000/5000] - Loss D: 1.1591, Loss G: 1.1622\n",
      "Epoch [4500/5000] - Loss D: 1.2016, Loss G: 1.1568\n",
      "Epoch [4999/5000] - Loss D: 0.7754, Loss G: 1.0544\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-75\\tratamento_cocomo81.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-75\\tratamento_desharnais.txt\n",
      "Epoch [0/5000] - Loss D: 1.3775, Loss G: 0.6955\n",
      "Epoch [500/5000] - Loss D: 0.8789, Loss G: 0.9701\n",
      "Epoch [1000/5000] - Loss D: 0.8242, Loss G: 1.5656\n",
      "Epoch [1500/5000] - Loss D: 1.0755, Loss G: 1.3067\n",
      "Epoch [2000/5000] - Loss D: 1.0784, Loss G: 1.4179\n",
      "Epoch [2500/5000] - Loss D: 0.6886, Loss G: 1.2698\n",
      "Epoch [3000/5000] - Loss D: 0.8672, Loss G: 1.2146\n",
      "Epoch [3500/5000] - Loss D: 1.0040, Loss G: 0.9741\n",
      "Epoch [4000/5000] - Loss D: 0.9462, Loss G: 1.2751\n",
      "Epoch [4500/5000] - Loss D: 0.8667, Loss G: 1.3898\n",
      "Epoch [4999/5000] - Loss D: 0.7311, Loss G: 1.1716\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-75\\tratamento_desharnais.txt\n",
      "Lendo arquivo: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\\MIMIC-75\\tratamento_maxwell.txt\n",
      "Epoch [0/5000] - Loss D: 1.3881, Loss G: 0.7053\n",
      "Epoch [500/5000] - Loss D: 1.3025, Loss G: 0.8192\n",
      "Epoch [1000/5000] - Loss D: 1.1365, Loss G: 0.7200\n",
      "Epoch [1500/5000] - Loss D: 1.1082, Loss G: 1.1009\n",
      "Epoch [2000/5000] - Loss D: 0.7368, Loss G: 1.9034\n",
      "Epoch [2500/5000] - Loss D: 1.2022, Loss G: 0.9819\n",
      "Epoch [3000/5000] - Loss D: 0.5865, Loss G: 1.7438\n",
      "Epoch [3500/5000] - Loss D: 0.9896, Loss G: 2.2983\n",
      "Epoch [4000/5000] - Loss D: 1.0889, Loss G: 1.1220\n",
      "Epoch [4500/5000] - Loss D: 1.0809, Loss G: 1.1774\n",
      "Epoch [4999/5000] - Loss D: 0.6747, Loss G: 1.5182\n",
      "Arquivo gerado: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\\MIMIC-75\\tratamento_maxwell.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configuração da semente para reprodutibilidade\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Definir a arquitetura da GAN\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Função para treinar a GAN\n",
    "def train_gan(real_data, num_features, latent_dim, num_samples, num_epochs=5000, batch_size=32):\n",
    "    scaler = MinMaxScaler()\n",
    "    real_data = scaler.fit_transform(real_data)\n",
    "    real_data = torch.tensor(real_data, dtype=torch.float32)\n",
    "\n",
    "    generator = Generator(latent_dim, num_features)\n",
    "    discriminator = Discriminator(num_features)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(max(1, real_data.size(0) // batch_size)):\n",
    "            idx = np.random.randint(0, real_data.size(0), batch_size)\n",
    "            real_samples = real_data[idx]\n",
    "\n",
    "            real_labels = torch.ones((real_samples.size(0), 1))\n",
    "            fake_labels = torch.zeros((real_samples.size(0), 1))\n",
    "\n",
    "            noise = torch.randn((real_samples.size(0), latent_dim))\n",
    "            fake_samples = generator(noise)\n",
    "\n",
    "            real_preds = discriminator(real_samples)\n",
    "            fake_preds = discriminator(fake_samples.detach())\n",
    "\n",
    "            loss_real = criterion(real_preds, real_labels)\n",
    "            loss_fake = criterion(fake_preds, fake_labels)\n",
    "            loss_D = loss_real + loss_fake\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        noise = torch.randn((batch_size, latent_dim))\n",
    "        fake_samples = generator(noise)\n",
    "        fake_preds = discriminator(fake_samples)\n",
    "        loss_G = criterion(fake_preds, torch.ones((batch_size, 1)))\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] - Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "\n",
    "    noise = torch.randn((num_samples, latent_dim))\n",
    "    synthetic_data = generator(noise).detach().numpy()\n",
    "    synthetic_data = scaler.inverse_transform(synthetic_data)\n",
    "    return synthetic_data\n",
    "\n",
    "# Função para processar subpastas e gerar saídas\n",
    "def process_subfolders(input_directory, output_directory, total_samples=10000):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(root, input_directory)\n",
    "            output_subdir = os.path.join(output_directory, relative_path)\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "            if file.endswith('.txt'):\n",
    "                try:\n",
    "                    print(f\"Lendo arquivo: {filepath}\")\n",
    "                    df = pd.read_csv(filepath, delimiter=',')\n",
    "                    df = df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "                    if df.empty:\n",
    "                        print(f\"Arquivo {file} está vazio após a limpeza.\")\n",
    "                        continue\n",
    "\n",
    "                    num_features = df.shape[1]\n",
    "                    samples_per_dataset = total_samples // len(files)\n",
    "                    synthetic_data = train_gan(df.values, num_features, latent_dim=10, num_samples=samples_per_dataset)\n",
    "\n",
    "                    output_path = os.path.join(output_subdir, file)\n",
    "                    synthetic_df = pd.DataFrame(synthetic_data, columns=df.columns)\n",
    "                    synthetic_df.to_csv(output_path, sep=',', index=False)\n",
    "                    print(f\"Arquivo gerado: {output_path}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao processar {file}: {e}\")\n",
    "\n",
    "# Diretórios de entrada e saída\n",
    "input_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\2-geracao-variaveis\"\n",
    "output_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\abordagem2\\saida\\3-simulacao\"\n",
    "\n",
    "# Processar subpastas e gerar saídas\n",
    "process_subfolders(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
