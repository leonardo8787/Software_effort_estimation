{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'china.txt' contém 0 valores faltantes.\n",
      "Aplicando one-hot encoding no arquivo: china.txt\n",
      "Arquivo transformado salvo em: datasets_encoded\\encoded_china.txt\n",
      "Arquivo 'cocomo81.txt' contém 0 valores faltantes.\n",
      "Não foi encontrada nenhuma coluna categórica no arquivo: cocomo81.txt\n",
      "Arquivo 'desharnais.txt' contém 0 valores faltantes.\n",
      "Aplicando one-hot encoding no arquivo: desharnais.txt\n",
      "Arquivo transformado salvo em: datasets_encoded\\encoded_desharnais.txt\n",
      "Arquivo 'maxwell.txt' contém 2 valores faltantes.\n",
      "Coluna categórica 'dba': 2 valores faltantes preenchidos com a moda 'Relatnl'.\n",
      "Aplicando one-hot encoding no arquivo: maxwell.txt\n",
      "Arquivo transformado salvo em: datasets_encoded\\encoded_maxwell.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CALEO\\AppData\\Local\\Temp\\ipykernel_1924\\1004948224.py:65: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def is_categorical_numeric(column, data, unique_threshold=10, frequency_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Determina se uma coluna numérica deve ser tratada como categórica.\n",
    "\n",
    "    Args:\n",
    "        column (str): Nome da coluna.\n",
    "        data (pd.DataFrame): DataFrame contendo a coluna.\n",
    "        unique_threshold (int): Número máximo de valores únicos para considerar como categórico.\n",
    "        frequency_threshold (float): Frequência máxima de valores únicos em relação ao tamanho do dataset.\n",
    "\n",
    "    Returns:\n",
    "        bool: Verdadeiro se a coluna for categórica.\n",
    "    \"\"\"\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values > unique_threshold:\n",
    "        return False  # Muitos valores únicos, não é categórico\n",
    "    value_frequency = unique_values / len(data)\n",
    "    return value_frequency <= frequency_threshold  # Deve ter uma frequência pequena de valores únicos\n",
    "\n",
    "def one_hot_encode_datasets(input_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Aplica one-hot encoding em todas as bases de dados de um diretório que possuem colunas categóricas,\n",
    "    com tratamento de valores faltantes.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Diretório contendo os arquivos .txt de entrada.\n",
    "        output_directory (str): Diretório onde os arquivos transformados serão salvos.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            try:\n",
    "                # Carregar o dataset\n",
    "                data = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "                # Contar valores faltantes\n",
    "                missing_values_count = data.isnull().sum().sum()\n",
    "                print(f\"Arquivo '{filename}' contém {missing_values_count} valores faltantes.\")\n",
    "\n",
    "                # Identificar colunas categóricas do tipo objeto\n",
    "                categorical_columns = list(data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "                # Identificar colunas categóricas numéricas com base em critérios mais robustos\n",
    "                numeric_categorical_columns = [\n",
    "                    col for col in data.select_dtypes(include=['number']).columns\n",
    "                    if is_categorical_numeric(col, data) and col != data.columns[-1]  # Ignorar a coluna alvo\n",
    "                ]\n",
    "\n",
    "                # Combinar ambas as categorias identificadas\n",
    "                all_categorical_columns = categorical_columns + numeric_categorical_columns\n",
    "\n",
    "                # Tratar valores faltantes\n",
    "                # Preencher valores faltantes para colunas categóricas com a moda\n",
    "                for col in categorical_columns:\n",
    "                    if col in data.columns and data[col].isnull().sum() > 0:\n",
    "                        mode_value = data[col].mode()[0]\n",
    "                        missing_count = data[col].isnull().sum()\n",
    "                        print(f\"Coluna categórica '{col}': {missing_count} valores faltantes preenchidos com a moda '{mode_value}'.\")\n",
    "                        data[col].fillna(mode_value, inplace=True)\n",
    "                \n",
    "                # Preencher valores faltantes para colunas numéricas com a média\n",
    "                for col in data.select_dtypes(include=['number']).columns:\n",
    "                    if col in data.columns and data[col].isnull().sum() > 0:\n",
    "                        mean_value = data[col].mean()\n",
    "                        missing_count = data[col].isnull().sum()\n",
    "                        print(f\"Coluna numérica '{col}': {missing_count} valores faltantes preenchidos com a média '{mean_value:.2f}'.\")\n",
    "                        data[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "                if len(all_categorical_columns) > 0:\n",
    "                    print(f\"Aplicando one-hot encoding no arquivo: {filename}\")\n",
    "\n",
    "                    # Aplicar one-hot encoding\n",
    "                    data_encoded = pd.get_dummies(data, columns=all_categorical_columns, drop_first=False)\n",
    "\n",
    "                    # Garantir que a coluna alvo seja a última\n",
    "                    target_column = data.columns[-1]\n",
    "                    columns = [col for col in data_encoded.columns if col != target_column] + [target_column]\n",
    "                    data_encoded = data_encoded[columns]\n",
    "\n",
    "                    # Salvar o dataset transformado\n",
    "                    output_file_path = os.path.join(output_directory, f\"encoded_{filename}\")\n",
    "                    data_encoded.to_csv(output_file_path, index=False, sep=',')\n",
    "\n",
    "                    print(f\"Arquivo transformado salvo em: {output_file_path}\")\n",
    "                else:\n",
    "                    print(f\"Não foi encontrada nenhuma coluna categórica no arquivo: {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {filename}: {e}\")\n",
    "\n",
    "# Caminhos de entrada e saída\n",
    "input_directory = \"datasets\"\n",
    "output_directory = \"datasets_encoded\"\n",
    "\n",
    "# Aplicar one-hot encoding nos datasets\n",
    "one_hot_encode_datasets(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
