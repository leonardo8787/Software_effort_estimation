{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodar todos os códigos do diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando abordagem.ipynb...\n",
      "Executando processamento.ipynb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 10:54:38.416425: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 10:54:38.419983: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 10:54:38.462190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 10:54:39.478289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando saídas do processamento.ipynb...\n",
      "Processamento concluído. Saída salva em: ./processamento_executado.txt\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "\n",
    "def run_notebook(notebook_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Executa um notebook e opcionalmente salva o resultado no mesmo formato do notebook.\n",
    "    \"\"\"\n",
    "    # Abrir o notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Configurar o executor\n",
    "    executor = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "    \n",
    "    # Executar o notebook\n",
    "    executor.preprocess(notebook, {'metadata': {'path': './'}})\n",
    "    \n",
    "    # Salvar o notebook executado, se output_path for fornecido\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            nbformat.write(notebook, f)\n",
    "\n",
    "def save_notebook_outputs_to_txt(notebook_path, output_txt_path):\n",
    "    \"\"\"\n",
    "    Lê um notebook executado e salva as saídas das células no formato TXT.\n",
    "    \"\"\"\n",
    "    # Ler o notebook executado\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook_content = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Salvar as saídas no arquivo TXT\n",
    "    with open(output_txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "        for cell in notebook_content['cells']:\n",
    "            if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "                txt_file.write(\"\\n# Saída\\n\")\n",
    "                for output in cell['outputs']:\n",
    "                    if 'text' in output:\n",
    "                        txt_file.write(output['text'] + '\\n')\n",
    "                    elif 'data' in output and 'text/plain' in output['data']:\n",
    "                        txt_file.write(output['data']['text/plain'] + '\\n')\n",
    "\n",
    "# Caminhos dos notebooks e saída\n",
    "abordagem_notebook = './abordagem.ipynb'\n",
    "processamento_notebook = './processamento.ipynb'\n",
    "processamento_output_txt = './processamento_executado.txt'\n",
    "\n",
    "# Executar o primeiro notebook (abordagem.ipynb)\n",
    "print(\"Executando abordagem.ipynb...\")\n",
    "run_notebook(abordagem_notebook)\n",
    "\n",
    "# Executar o segundo notebook (processamento.ipynb)\n",
    "print(\"Executando processamento.ipynb...\")\n",
    "run_notebook(processamento_notebook)\n",
    "\n",
    "# Salvar as saídas do notebook \"processamento.ipynb\" no arquivo TXT\n",
    "print(\"Salvando saídas do processamento.ipynb...\")\n",
    "save_notebook_outputs_to_txt(processamento_notebook, processamento_output_txt)\n",
    "\n",
    "print(\"Processamento concluído. Saída salva em:\", processamento_output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Dataset             Model       MSE  RMSE       MAE  \\\n",
      "0    cleaned_cocomo81.txt  Regressão Linear  0.186184  None  0.083779   \n",
      "1  cleaned_desharnais.txt  Regressão Linear  0.175406  None  0.120379   \n",
      "2       cleaned_isbsg.txt  Regressão Linear  0.108375  None  0.100613   \n",
      "3     cleaned_maxwell.txt  Regressão Linear  0.147751  None  0.098961   \n",
      "4       cleaned_china.txt  Regressão Linear  0.019632  None  0.007178   \n",
      "5    cleaned_cocomo81.txt   Regressão Ridge  0.060793  None  0.048836   \n",
      "6  cleaned_desharnais.txt   Regressão Ridge  0.136007  None  0.087269   \n",
      "7       cleaned_isbsg.txt   Regressão Ridge  0.118609  None  0.097567   \n",
      "8     cleaned_maxwell.txt   Regressão Ridge  0.041876  None  0.034528   \n",
      "9       cleaned_china.txt   Regressão Ridge  0.028778  None  0.012308   \n",
      "\n",
      "           MAPE        R²  Explained Variance  Max Error  \n",
      "0  5.251383e+02  0.295982            0.377891   0.776781  \n",
      "1  7.977373e-01 -0.389023           -0.383452   0.491923  \n",
      "2  2.021612e+00  0.811896            0.867888   0.168246  \n",
      "3  8.588125e+13 -1.334617           -1.322351   0.422591  \n",
      "4  3.325078e-01  0.963524            0.963606   0.196719  \n",
      "5  1.044026e+03 -0.552633           -0.498812   0.115887  \n",
      "6  3.794746e-01  0.291323            0.432285   0.359499  \n",
      "7  1.619737e+00 -1.111705            0.004029   0.189074  \n",
      "8  1.716313e+00  0.576791            0.600173   0.084948  \n",
      "9  4.949846e-01  0.917878            0.917904   0.197713  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Caminho do arquivo\n",
    "processamento_output_txt = './processamento_executado.txt'\n",
    "\n",
    "# Inicializar lista para armazenar os resultados\n",
    "results = []\n",
    "\n",
    "# Processar o arquivo\n",
    "with open(processamento_output_txt, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Detectar nome do dataset e modelo\n",
    "        if line.startswith(\"Arquivo:\"):\n",
    "            parts = line.split(\" - \")\n",
    "            current_dataset = parts[0].split(\":\")[1].strip()\n",
    "            current_model = parts[1] if len(parts) > 1 else None\n",
    "            \n",
    "            # Redefinir métricas para o novo bloco\n",
    "            mse = None\n",
    "            rmse = None\n",
    "            mae = None\n",
    "            mape = None\n",
    "            r2 = None\n",
    "            explained_var = None\n",
    "            max_err = None\n",
    "\n",
    "        # Detectar métricas\n",
    "        elif \"Mean Squared Error\" in line:\n",
    "            mse = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"Root Mean Squared Error\" in line:\n",
    "            rmse = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"Mean Absolute Error\" in line:\n",
    "            mae = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"Mean Absolute Percentage Error\" in line:\n",
    "            mape = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"R² Score\" in line:\n",
    "            r2 = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"Explained Variance Score\" in line:\n",
    "            explained_var = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        elif \"Max Error\" in line:\n",
    "            max_err = float(re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", line).group())\n",
    "        \n",
    "        # Adicionar resultados ao final do bloco\n",
    "        elif line.startswith(\"--------------------------------------------------\"):\n",
    "            results.append({\n",
    "                \"Dataset\": current_dataset,\n",
    "                \"Model\": current_model,\n",
    "                \"MSE\": mse,\n",
    "                \"RMSE\": rmse,\n",
    "                \"MAE\": mae,\n",
    "                \"MAPE\": mape,\n",
    "                \"R²\": r2,\n",
    "                \"Explained Variance\": explained_var,\n",
    "                \"Max Error\": max_err,\n",
    "            })\n",
    "\n",
    "# Criar DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Salvar os resultados em um arquivo CSV\n",
    "df_results.to_csv('./resultados/4/tabela_resultados_processamento.csv', index=False)\n",
    "\n",
    "# Exibir os primeiros resultados diretamente no terminal\n",
    "print(df_results.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
