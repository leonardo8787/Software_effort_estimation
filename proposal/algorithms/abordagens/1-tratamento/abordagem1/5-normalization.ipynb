{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo normalizado salvo em: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\output\\1-saida\\2-saida_cocomo81.txt\n",
      "Arquivo normalizado salvo em: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\output\\1-saida\\2-saida_encoded_china.txt\n",
      "Arquivo normalizado salvo em: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\output\\1-saida\\2-saida_encoded_desharnais.txt\n",
      "Arquivo normalizado salvo em: C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\output\\1-saida\\2-saida_encoded_maxwell.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_dataset(data):\n",
    "    \"\"\"\n",
    "    Aplica normalização Min-Max em colunas numéricas do dataset usando a fórmula manual.\n",
    "\n",
    "    Fórmula: X_norm = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame a ser normalizado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com colunas numéricas normalizadas e valores booleanos convertidos para 0 e 1.\n",
    "    \"\"\"\n",
    "    # Converter valores booleanos para 0 e 1\n",
    "    boolean_columns = data.select_dtypes(include=['bool']).columns\n",
    "    for col in boolean_columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "    # Normalizar colunas numéricas\n",
    "    numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "    for col in numeric_columns:\n",
    "        col_min = data[col].min()\n",
    "        col_max = data[col].max()\n",
    "        if col_max != col_min:  # Evitar divisão por zero\n",
    "            data[col] = (data[col] - col_min) / (col_max - col_min)\n",
    "        else:\n",
    "            data[col] = 0  # Se todos os valores são iguais, normaliza para 0\n",
    "    return data\n",
    "\n",
    "def process_datasets(input_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Normaliza os datasets e salva os arquivos processados.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Diretório contendo os arquivos .txt de entrada.\n",
    "        output_directory (str): Diretório onde os arquivos transformados serão salvos.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            try:\n",
    "                # Carregar o dataset\n",
    "                data = pd.read_csv(file_path, delimiter=',')\n",
    "\n",
    "                # Aplicar normalização\n",
    "                data_normalized = normalize_dataset(data)\n",
    "\n",
    "                # Salvar o dataset transformado\n",
    "                output_file_path = os.path.join(output_directory, f\"2-saida_{filename}\")\n",
    "                data_normalized.to_csv(output_file_path, index=False, sep=',')\n",
    "\n",
    "                print(f\"Arquivo normalizado salvo em: {output_file_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {filename}: {e}\")\n",
    "\n",
    "# Caminhos de entrada e saída\n",
    "input_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\datasets-usaveis\"\n",
    "output_directory = r\"C:\\Users\\CALEO\\OneDrive - Hexagon\\Documents\\GitHub\\Software_effort_estimation\\proposal\\algorithms\\abordagens\\output\"\n",
    "\n",
    "# Processar os datasets\n",
    "process_datasets(input_directory, output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
