{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the datasets folder\n",
    "datasets_path = './datasets'\n",
    "\n",
    "# Read and display each txt file separately\n",
    "if os.path.exists(datasets_path):\n",
    "    for filename in os.listdir(datasets_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(datasets_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                print(f\"Contents of {filename}:\\n{content}\\n{'-'*40}\\n\")\n",
    "else:\n",
    "    print(\"The datasets folder does not exist or no .txt files were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Instale o PyCaret (caso ainda não tenha feito isso)\n",
    "!pip install pycaret\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pycaret.regression import setup, compare_models\n",
    "\n",
    "# Caminho para a pasta datasets\n",
    "datasets_path = './datasets'\n",
    "output_file = 'melhores_modelos.txt'\n",
    "\n",
    "# Limpar o conteúdo anterior do arquivo de saída\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"Melhores Modelos para Cada Dataset\\n\")\n",
    "    f.write(\"=\"*40 + \"\\n\\n\")\n",
    "\n",
    "# Verificar se a pasta existe e ler todos os arquivos txt\n",
    "if os.path.exists(datasets_path):\n",
    "    for filename in os.listdir(datasets_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(datasets_path, filename)\n",
    "            \n",
    "            # Carregar os dados\n",
    "            try:\n",
    "                data = pd.read_csv(file_path)\n",
    "                print(f\"Lendo e processando: {filename}\")\n",
    "                print(f\"Colunas disponíveis no arquivo {filename}: {data.columns.tolist()}\\n\")\n",
    "                \n",
    "                # Usar a última coluna como variável alvo\n",
    "                target_column = data.columns[-1]\n",
    "                print(f\"Usando a coluna '{target_column}' como variável alvo.\\n\")\n",
    "\n",
    "                # Configuração do PyCaret para o problema de regressão\n",
    "                reg = setup(data, target=target_column)\n",
    "                \n",
    "                # Comparar todos os modelos de regressão\n",
    "                best_model = compare_models()\n",
    "                print(f\"Melhor modelo para {filename}: {best_model}\\n{'-'*40}\\n\")\n",
    "                \n",
    "                # Salvar o melhor modelo no arquivo\n",
    "                with open(output_file, 'a') as f:\n",
    "                    f.write(f\"Arquivo: {filename}\\n\")\n",
    "                    f.write(f\"Melhor Modelo: {best_model}\\n\")\n",
    "                    f.write(\"-\"*40 + \"\\n\\n\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {filename}: {e}\\n\")\n",
    "else:\n",
    "    print(\"A pasta 'datasets' não existe ou está vazia.\")\n",
    "    \n",
    "print(f\"Os melhores modelos foram salvos em {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pycaret.regression import setup, create_model, stack_models, pull\n",
    "\n",
    "# Caminho para a pasta datasets\n",
    "datasets_path = './datasets'\n",
    "\n",
    "# Melhores modelos escolhidos manualmente para cada dataset\n",
    "best_models = {\n",
    "    \"cleaned_cocomo81.txt\": \"dt\",  # DecisionTreeRegressor\n",
    "    \"cleaned_desharnais.txt\": \"huber\",  # HuberRegressor\n",
    "    \"cleaned_isbsg.txt\": \"lr\",  # LinearRegression\n",
    "    \"cleaned_maxwell.txt\": \"catboost\",  # CatBoostRegressor\n",
    "    \"cleaned_china.txt\": \"lr\"  # LinearRegression\n",
    "}\n",
    "\n",
    "# Lista para armazenar os resultados\n",
    "results_list = []\n",
    "\n",
    "# Verificar se a pasta existe e ler todos os arquivos txt\n",
    "if os.path.exists(datasets_path):\n",
    "    for filename in os.listdir(datasets_path):\n",
    "        if filename in best_models:\n",
    "            file_path = os.path.join(datasets_path, filename)\n",
    "            \n",
    "            try:\n",
    "                # Carregar os dados\n",
    "                data = pd.read_csv(file_path)\n",
    "                print(f\"\\nLendo e processando: {filename}\")\n",
    "                \n",
    "                # Usar a última coluna como variável alvo\n",
    "                target_column = data.columns[-1]\n",
    "                print(f\"Usando a coluna '{target_column}' como variável alvo.\\n\")\n",
    "\n",
    "                # Configuração do PyCaret para o problema de regressão\n",
    "                reg = setup(data, target=target_column, verbose=False)\n",
    "                \n",
    "                # Criar os modelos individuais\n",
    "                model1 = create_model(best_models[filename])\n",
    "                \n",
    "                # Adicionar mais modelos conforme necessário e criar um ensemble\n",
    "                if best_models[filename] == \"lr\":\n",
    "                    model2 = create_model(\"dt\")  # Adicionando um Decision Tree como exemplo\n",
    "                else:\n",
    "                    model2 = create_model(\"lr\")  # Adicionando uma Regressão Linear como exemplo\n",
    "                \n",
    "                # Criar o ensemble usando a abordagem de empilhamento\n",
    "                ensemble_model = stack_models([model1, model2])\n",
    "                \n",
    "                # Obter o DataFrame de métricas de desempenho\n",
    "                metrics_df = pull()\n",
    "                \n",
    "                # Adicionar o nome do arquivo ao DataFrame\n",
    "                metrics_df['Dataset'] = filename\n",
    "                \n",
    "                # Armazenar os resultados\n",
    "                results_list.append(metrics_df)\n",
    "                \n",
    "                print(f\"Modelo Ensemble criado para {filename}\\n{'-'*40}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {filename}: {e}\\n\")\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "if results_list:\n",
    "    final_results_df = pd.concat(results_list)\n",
    "    # Reorganizar as colunas para mostrar o nome do dataset primeiro\n",
    "    final_results_df = final_results_df[['Dataset'] + [col for col in final_results_df.columns if col != 'Dataset']]\n",
    "    \n",
    "    # Salvar a tabela de resultados em um arquivo TXT\n",
    "    output_file_path = 'ensemble_results.txt'\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(\"Tabela de Resultados:\\n\")\n",
    "        file.write(final_results_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nTabela de Resultados salva em: {output_file_path}\")\n",
    "else:\n",
    "    print(\"Nenhum resultado foi gerado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
